p8105_hw5_jz3900
================
ELisajava
2024-11-11

# Import necessary libraries

``` r
library(tidyverse) 
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(broom)
library(ggplot2)
set.seed(1)
```

# Problem 1

``` r
# Define a function to check for duplicate birthdays in a group
check_duplicate_birthday <- function(n) {
  sampled_birthdays <- sample(1:365, n, replace = TRUE)  # Generate sample birthdays randomly
  any(duplicated(sampled_birthdays))  # Return TRUE if duplicates are found
}

# Set up group sizes and initialize a vector for storing probabilities
group_sizes <- 2:50
probabilities <- numeric(length(group_sizes))

# Simulate the probability of duplicated birthdays for each group size
probabilities <- sapply(group_sizes, function(n) {
  mean(replicate(10000, check_duplicate_birthday(n)))
})

# Prepare data for visualization
results_data <- data.frame(GroupSize = group_sizes, Probability = probabilities)

# Generate the plot
ggplot(results_data, aes(x = GroupSize, y = Probability)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of Shared Birthdays by Group Size",
    x = "Number of People in Group (Group Size)",
    y = "Probability of Shared Birthday",
    caption = "Based on 10,000 simulations per group size"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

![](p8105_hw5_jz3900_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

The plot illustrates that as the group size grows, the likelihood of at
least two people sharing a birthday rises sharply. With just 23 people
in a group, the probability surpasses 50%. As the group size nears 50,
the probability approaches certainty 1.00.

# Problem 2

## Define parameters and create datasets

``` r
# Define parameters
params <- list(
  sample_size = 30,
  sample_var = 5,
  mu_values = seq(0, 6, by = 1),
  alpha = 0.05,
  n_sim = 5000
)

# Function to simulate data and perform t-tests
simulate_t_test <- function(n, mu, sigma) {
  results <- replicate(params$n_sim, { 
    x <- rnorm(n, mean = mu, sd = sigma)  # Generate random data
    test <- t.test(x, mu = 0)  # Perform t-test
    tidy_result <- tidy(test)  # Extract estimate and p-value
    list(estimate = tidy_result$estimate, p_value = tidy_result$p.value)
  }, simplify = FALSE)
  
  # Convert list to data frame
  data.frame(
    estimate = sapply(results, `[[`, "estimate"),
    p_value = sapply(results, `[[`, "p_value")
  )
}
```

## Simulation for each value of ‘mu’

``` r
# Run simulations for each value of mu and combine the results
simulation_results <- lapply(params$mu_values, function(mu) {
  simulate_t_test(params$sample_size, mu, params$sample_var)
})
names(simulation_results) <- as.character(params$mu_values)

# Merge all results into one data frame 
simulation_data <- bind_rows(simulation_results, .id = "mu") %>%
  mutate(mu = as.numeric(mu))

# Calculate the statistical power for each mean value 
power_data <- simulation_data %>%
  group_by(mu) %>%
  summarize(power = mean(p_value < params$alpha))

# Draw a statistical power graph
ggplot(power_data, aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "The relationship between statistical power of t-test and true mean",
    x = "True mean", y = "Statistical power"
  ) +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```

![](p8105_hw5_jz3900_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
# Calculate the average estimate for all samples
avg_estimate_data <- simulation_data %>%
  group_by(mu) %>%
  summarize(average_estimate = mean(estimate))

# Average estimate when only the null hypothesis is rejected
rejected_estimate_data <- simulation_data %>%
  filter(p_value < params$alpha) %>%
  group_by(mu) %>%
  summarize(average_estimate_rejected = mean(estimate))
```

The plot demonstrates a positive correlation between effect size (true
mean, μ) and statistical power. As the effect size increases, the
statistical power rises, indicating that the t-test becomes more
effective at identifying true effects with larger effect sizes, thereby
enhancing its reliability.

At smaller effect sizes (e.g., μ = 0, 1, 2), the power remains
relatively low, reflecting a reduced likelihood of detecting a true
effect. However, as μ increases to values such as 4, 5, or 6, the power
nears 1, signifying that the test becomes almost certain to detect the
true effect.

## Create estimates plot

``` r
# Combine data for plotting
avg_estimate_data$type <- "All Samples"
rejected_estimate_data$type <- "Samples that reject the null hypothesis"

combined_estimate_data <- bind_rows(
  avg_estimate_data %>% rename(average = average_estimate),
  rejected_estimate_data %>% rename(average = average_estimate_rejected)
)

# Plot the average estimate
ggplot(combined_estimate_data, aes(x = mu, y = average, color = type, linetype = type)) +
  geom_line() +
  geom_point() +
  scale_color_manual(values = c("blue", "red")) +
  labs(
    title = "Relationship between Mean Estimate and True μ",
    x = "True μ",
    y = "Average Estimate",
    color = "Data Type",
    linetype = "Data Type",
    caption = "Based on 5,000 simulations per μ value"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom"
  )
```

![](p8105_hw5_jz3900_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

The plot presents two sets of average estimates corresponding to
different true means (μ):

- **Blue Line (All Samples):** This represents the average estimate of μ
  across all samples, regardless of whether the null hypothesis was
  rejected.  
- **Red Line (Samples that reject the null hypothesis):** This depicts
  the average estimate of μ exclusively for samples where the null
  hypothesis was rejected.

The red line consistently lies above the blue line, particularly for
lower values of μ. This suggests that the average estimate of μ for
tests resulting in rejection of the null hypothesis tends to
overestimate the true mean.

Notably, the sample average of μ-hat for tests where the null is
rejected does not accurately reflect the true value of μ; instead, it is
systematically higher. This phenomenon arises due to selection bias,
where samples with stronger observed effects (i.e., larger estimates)
are more likely to result in rejection of the null hypothesis.
